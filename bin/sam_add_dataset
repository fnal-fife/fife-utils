#!/usr/bin/env python

import optparse
import getpass
import os
import sys

import pprint
import samweb_client
import datetime
import logging
import subprocess
import re
import time
import socket

#
# old python compatability hacks
#
try:
    import json
except:
    import simplejson as json

try:
   import uuid
except:
   class uuid:
       def uuid4():
         return "%s-%s-%s-%s-%s" % (
              hex(int(time.time()))[2:],
              hex(os.getpid())[2:],
              hex(os.getppid())[2:],
              hex(os.getpid())[2:],
              ''.join([hex(int(x))[2:] for x in socket.gethostbyname(socket.gethostname()).split('.')])
            )
       uuid4 = staticmethod(uuid4)
          
#from fife_sam_utils import samprefix, is_cert_valid, has_uuid_prefix
from fife_sam_utils import samprefix, has_uuid_prefix




def get_standard_certificate_path(options):
  logging.info('looking for cert')

  if options.cert:
    cert = options.cert

  else:
    cert = os.environ.get('X509_USER_PROXY')
    if not cert:
      cert = os.environ.get('X509_USER_CERT')
      key = os.environ.get('X509_USER_KEY')
      if cert and key: cert = (cert, key)
    if not cert:
      #look in standard place for cert
      proxypath = '/tmp/x509up_u%d' % os.getuid()
      #if os.path.exists(proxypath) and is_cert_valid():
      if os.path.exists(proxypath):
        cert = proxypath
    if not cert:
      logging.info('trying to create cert for you as none were found')
      if os.environ.get('EXPERIMENT') and os.environ.get('ROLE'):
        EXPERIMENT = os.environ.get('EXPERIMENT')
        ROLE = os.environ.get('ROLE')

        a = os.system("kx509")
        b = os.system("voms-proxy-init \
                      -rfc \
                      -noregen \
                      -voms fermilab:/fermilab/"+EXPERIMENT+"/Role="+ROLE)

        if a != 0 and b != 0:
          sys.exit('there was a problem running kx509 and or voms-proxy-init')
        else:
          proxypath = '/tmp/x509up_u%d' % os.getuid()
          if os.path.exists(proxypath):
            os.environ['X509_USER_PROXY'] = proxypath
            cert = proxypath
      else:
        sys.exit("please make sure the environment variables $EXPERIMENT and $ROLE are set\nexamples of $ROLE are Analysis or Production")

  if not cert:
    sys.exit("unable to find cert and unable to make one")

  logging.info('cert is %s' % cert)
  return cert



def get_experiment(options):
  logging.info('looking for experiment')

  if options.experiment:
    experiment = options.experiment
  elif 'SAM_EXPERIMENT' in os.environ:
    experiment = os.environ.get("SAM_EXPERIMENT")
  else:
    sys.exit("you must specify an experiment as an option or set $SAM_EXPERIMENT")

  logging.info('experiment is %s' % experiment)
  return experiment



def getJSONMetadata(jsonFile, tag):
  logging.info('looking for json metadata from user at %s' % jsonFile)
  metadata = None

  try:
    f = open(jsonFile)
    metadata = json.loads(f.read())
    f.close()
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('extracted user metadata which is %s' % metadata)


  if "data_tier" in metadata:
    if metadata["data_tier"].endswith("-user"):
      pass
    else:
      metadata["data_tier"] = metadata["data_tier"]+"-user"


  logging.info('updating the metadata with Dataset.Tag: %s' % tag)
  metadata.update( {"Dataset.Tag": tag } )

  logging.info('the metadata is now %s' % metadata)
  return metadata



def getFileList(txtFile):
  logging.info('trying to create a python list of files from file %s' % txtFile)
  fileList = []
  
  try:
    f = open(txtFile)
    for line in f:
      if line[0] != '#':
        fileList.append( os.path.abspath(line.strip('\n')) )
    f.close()
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('the python list is %s' % fileList)
  return fileList



def getFileListFromDir(directory, recurse):
  logging.info('trying to create a python list of files from directory %s with recurse level set to %s' % (directory, recurse))
    
  fileList = []
    
  for root, dirs, files in os.walk(directory):
        
    for fileName in files:
            
      filePath = os.path.join(root, fileName)
      fileList.append( os.path.abspath(filePath) )
    
    if recurse == False:
        break

  logging.info('the python list is %s' % fileList)
  return fileList



def getFileListFromPipe():
  logging.info('trying to create a python list of files from a pipe')
  fileList = []

  try:
    for line in sys.stdin:
      fileList.append( os.path.abspath(line.strip('\n')) )
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('the python list is %s' % fileList)
  return fileList



def declareFile(samweb, metadata):
  logging.info('trying to declare the metadata to sam which is %s' % json.dumps(metadata))

  try:
    samweb.declareFile( metadata )
  except Exception, e:
    logging.info(str(e))
  else:
    logging.info('the metadata was declared to sam')



def renameFile(file):

  fileName = os.path.basename(file)
  dirName = os.path.dirname(file)

  if not has_uuid_prefix(fileName):
    logging.info('trying to rename %s on disk with a uuid' % file)

    uniquifier = str(uuid.uuid4()) + '-'

    if dirName == '':
      newFileName = uniquifier + fileName
    else:
      newFileName = dirName + '/' + uniquifier + fileName

    try:
      os.rename(file, newFileName)
    except Exception, e:
      sys.exit('oops: %s' % e)

    print 'renamed ' + fileName + ' to ' + os.path.basename(newFileName)
    logging.info('its location is %s' % dirName)

  else:
    logging.info('uuid detected for %s therefore not renaming' % file)
    if dirName == '':
      newFileName = fileName
    else:
      newFileName = dirName + '/' + fileName

  return {"file_name": os.path.basename(newFileName), "location": dirName}



def statBuildMetaData(file):
  logging.info('trying to stat %s for its size' % file)
  
  try:
    statinfo = os.stat(file)
  except Exception, e:
    sys.exit('oops: %s' % e)

  size = statinfo.st_size
        
  metadata = {"file_name": file, "file_type": "unknown", "file_size": size}
  
  logging.info('just built generic json metadata object for this file %s which will be updated' % metadata)
  
  return metadata



def declareFileLocation(samweb, fileName, location):
  logging.info('trying to declare file location to sam with filename of %s and location of %s' % (fileName, location))
  
  location = samprefix(location) + location

  try:
    samweb.addFileLocation(fileName, location)
  except Exception, e:
    if "Location" and "not found" in str(e):
      data_disks = samweb.listDataDisks()
      for item in data_disks:
        logging.info("valid data disk: " + item['mount_point'])
      sys.exit('oops: this is not a valid sam path')
    else:
      sys.exit('oops: %s' % e)
  logging.info('file location was declared to sam')



def get_tag(options, datasetName):
  logging.info('trying to resolve a tag')
  
  if options.tag:
    tag = options.tag
    logging.info('the tag is %s' % tag)
    return tag
  else:
    tag = datasetName
    logging.info('the tag is %s' % tag)
    return tag



def get_dataset_name(options, user):
  logging.info('trying to resolve a dataset name')

  if options.name:
    datasetName = options.name
  else:
    datasetName = "userdataset_" + user + "_" + str(datetime.datetime.now().strftime("%Y-%m-%d-%H_%M_%S"))
  logging.info('the dataset name is %s' % datasetName)
  return datasetName



def createDefinition(samweb, definitionName, dimensions):
  logging.info('trying to create definition %s with dimensions %s to sam' % (definitionName, dimensions))
  
  try:
    samweb.createDefinition(definitionName, dimensions)
  except Exception, e:
    sys.exit('oops: %s' % e)
  logging.info('dataset definition created')



class Sam_Metadata_Dumper_Parser:
 
  SAM_METADATA = None
 
  def __init__(self, file, samweb):
    self.file = file
    self.samweb = samweb
    
    
  def get_json(self):
    logging.info('trying to create subprocess for sam_metadata_dumper')     
   
    try:
      a = json.loads( subprocess.Popen(["sam_metadata_dumper", self.file],stdout=subprocess.PIPE).stdout.read() )
    except Exception, e:
      sys.exit('oops: %s' % e)

    logging.info('extracted the following metadata to be formated %s', a)        

    self.SAM_METADATA = a[self.file]

    return self.SAM_METADATA


  def format_json(self):
    logging.info('formatting the extracted metadata')  
  
    keys = self.SAM_METADATA.keys()
    application = {}
    found = False

    if 'applicationFamily' in keys:
      found = True
      application['family'] = self.SAM_METADATA['applicationFamily']
      del self.SAM_METADATA['applicationFamily']
    if 'applicationVersion' in keys:
      found = True
      application['version'] = self.SAM_METADATA['applicationVersion']
      del self.SAM_METADATA['applicationVersion']
    if 'process_name' in keys:
      found = True
      application['name'] = self.SAM_METADATA['process_name']
      del self.SAM_METADATA['process_name']

    if found:
      self.SAM_METADATA["application"] = application
                
    if 'dataTier' in keys:
      self.SAM_METADATA['data_tier'] = self.SAM_METADATA['dataTier']
      del self.SAM_METADATA['dataTier']
    if 'fileType' in keys:
      self.SAM_METADATA['file_type'] = self.SAM_METADATA['fileType']
      del self.SAM_METADATA['fileType']
    if 'streamName' in keys:
      self.SAM_METADATA['data_stream'] = self.SAM_METADATA['streamName']
      del self.SAM_METADATA['streamName']

    if 'first_event' in keys:
      if isinstance(self.SAM_METADATA['first_event'], list):
        self.SAM_METADATA['first_event'] = self.SAM_METADATA['first_event'][-1]
    if 'last_event' in keys:
      if isinstance(self.SAM_METADATA['last_event'], list):
        self.SAM_METADATA['last_event'] = self.SAM_METADATA['last_event'][-1]

    try:
      self.samweb.validateFileMetadata(md=self.SAM_METADATA)
    except Exception, e:
      lines = str(e.msg).split('\n')
      for line in lines:
        if 'Unknown' in line:
          unknown_md_item =  line.split("'")[-2]
          if unknown_md_item in keys:
            logging.info('invalid metadata item %s deleting it', unknown_md_item)
            del self.SAM_METADATA[unknown_md_item]

    for key, value in self.SAM_METADATA.iteritems():
      if isinstance(value, int):
        self.SAM_METADATA[key] = str(value)
        
    return self.SAM_METADATA



def check_options(p, options):
  logging.info('checking options')

  errors = "\n"
  supported_subprocesses = ["sam_metadata_dumper"]

  if options.file and options.directory:
    errors += "you must specify either a text file or a directory not both\n"

  if options.file == None and options.directory == None:
    errors += "you must specify either a text file or a directory\n"

  if options.subprocess and options.subprocess not in supported_subprocesses:
    errors += "only the following subprocesses are supported: " + ', '.join(supported_subprocesses)

  if errors != "\n":
    p.error(errors)

  logging.info('options good')



def main():

  user = getpass.getuser()
  
  """runs program and handles command line options"""

  p = optparse.OptionParser(description='Add a group of files to SAM and create a dataset out of it.',
                            prog='sam_add_dataset',
                            version='sam_add_dataset 0.9',
                            usage='%prog <-f file | -d directory> [options]')


  p.add_option('-e', '--experiment', help='use this experiment server defaults to $SAM_EXPERIMENT if not set')
  p.add_option('-u', '--user', help='default is %s' % user)
  p.add_option('-t', '--tag', help='the value for Dataset.Tag which will be used to distinguish this new dataset default format is user+date')
  p.add_option('-n', '--name', help='the dataset name default is userdataset+user+date')
  p.add_option('-d', '--directory', help='directory of files to create dataset with')
  p.add_option('-r', '--recurse', action ='store_true', default=False, help='walk down all levels of directory')
  p.add_option('-f', '--file', help='file of file paths to create dataset with')
  p.add_option('-m', '--metadata', help='json file of metadata you would like added to all files')
  p.add_option('-s',  '--subprocess', help='execute a child program in a new process to extract metadata only sam_metadata_dumper currently supported')
  p.add_option('-c', '--cert', help='x509 certificate for authentication. If not specified, use $X509_USER_PROXY, $X509_USER_CERT/$X509_USER_KEY or standard grid proxy location')
  p.add_option('-v', '--verbose', action ='store_true', help='returns verbose output')
  
  
  options, arguments = p.parse_args()

  
  if options.verbose:
    logging.basicConfig(level=logging.DEBUG)
  else:
    logging.disable(logging.CRITICAL)


  if len(sys.argv) == 1:
    p.print_help()
    return


  check_options(p, options)
  
  experiment = get_experiment(options)

  if options.user:
    user = options.user

  cert = get_standard_certificate_path(options)

  samweb = samweb_client.SAMWebClient(experiment=experiment, cert=cert)

 
  jsonFile = options.metadata
  
  datasetName = get_dataset_name(options, user)

  tag = get_tag(options, datasetName)

  logging.info('the options are %s' % options)
  logging.info('the arguments are %s' % arguments)
  logging.info('the user is %s' % user)


  if 5 > 3:  #still need to figure out this condition

    if jsonFile:
      universalMD = getJSONMetadata(options.metadata, tag)
    else:
      universalMD = {"Dataset.Tag": tag}

    if options.directory:
      if os.path.isdir(options.directory):
        fileList = getFileListFromDir(options.directory, options.recurse)
    elif options.file == '-':
      fileList = getFileListFromPipe()
    else:
      fileList = getFileList(options.file)


    logging.info('entering for loop to process all the files to create the dataset')
    for file in fileList:
      logging.info('processing %s' % file)
      
      fileMD = {}
      
      if options.subprocess:
        dumperObject = Sam_Metadata_Dumper_Parser(file, samweb)
        dumperObject.get_json()
        sam_metadata_dumper_metadata = dumperObject.format_json()
        fileMD.update(sam_metadata_dumper_metadata) 
        
      fileMD.update( statBuildMetaData(file) )
      renamedFile = renameFile(file)
      fileLocation = renamedFile.pop("location")
            
      fileMD.update(renamedFile)
      fileMD.update(universalMD)
    
      declareFile(samweb, fileMD)
      declareFileLocation(samweb, fileMD["file_name"], fileLocation)

    logging.info('for loop is done')
    
    
    dimension = "Dataset.Tag " + tag
    createDefinition(samweb, datasetName, dimension)


    logging.info('PROGRAM SUCCESS')
    print 'the dataset with name ' + datasetName + ' was created'


  else:
    #p.print_help()
    p.error("incorrect number of arguments")



if __name__ == '__main__':
  main()
