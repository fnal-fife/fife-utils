#!/usr/bin/env python

import optparse
import json
import getpass
import os
import sys
import uuid
import pprint
import samweb_client
import datetime
import logging
import subprocess
from fife_sam_utils import samprefix



def get_standard_certificate_path(options):
  logging.info('looking for cert')
    
  if options.cert:
    cert = options.cert
    logging.info('cert is %s' % cert)
    return cert

  else:
    cert = os.environ.get('X509_USER_PROXY')
    if not cert:
      cert = os.environ.get('X509_USER_CERT')
      key = os.environ.get('X509_USER_KEY')
      if cert and key: cert = (cert, key)
    if not cert:
      #look in standard place for cert
      proxypath = '/tmp/x509up_u%d' % os.getuid()
      if os.path.exists(proxypath):
        cert = proxypath
    logging.info('cert is %s' % cert)
    return cert



def get_experiment(options):
  logging.info('looking for experiment')

  if options.experiment:
    experiment = options.experiment
  elif 'SAM_EXPERIMENT' in os.environ:
    experiment = os.environ.get("SAM_EXPERIMENT")
  else:
    sys.exit("you must specify an experiment as an option or set $SAM_EXPERIMENT")

  logging.info('experiment is %s' % experiment)
  return experiment



def getJSONMetadata(jsonFile, tag):
  logging.info('looking for json metadata from user at %s' % jsonFile)
  metadata = None
  
  try:
    with open(jsonFile) as f:
      metadata = json.loads(f.read())
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('extracted user metadata which is %s' % metadata)

  logging.info('updating the metadata with Dataset.Tag: %s' % tag)
  metadata.update( {"Dataset.Tag": tag } )

  logging.info('the metadata is now %s' % metadata)
  return metadata



def getFileList(txtFile):
  logging.info('trying to create a python list of files from file %s' % txtFile)
  fileList = []
  
  try:
    with open(txtFile) as f:
      for line in f:
        fileList.append(line.strip('\n'))
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('the python list is %s' % fileList)
  return fileList



def getFileListFromDir(directory, recurse):
  logging.info('trying to create a python list of files from directory %s with recurse level set to %s' % (directory, recurse))
    
  fileList = []
    
  for root, dirs, files in os.walk(directory):
        
    for fileName in files:
            
      filePath = os.path.join(root, fileName)
      fileList.append(filePath)
    
    if recurse == False:
        break

  logging.info('the python list is %s' % fileList)
  return fileList



def declareFile(samweb, metadata):
  logging.info('trying to declare the metadata to sam which is %s' % json.dumps(metadata))
   
  try:
    samweb.declareFile( metadata )
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('the metadata was declared to sam')



def renameFile(file):
                       
  logging.info('trying to rename %s on disk with a uuid' % file)
                       
  uniquifier = str(uuid.uuid4()) + '-'
        
  fileName = os.path.basename(file)
  dirName = os.path.dirname(file)
  
  if dirName == '':
    newFileName = uniquifier + fileName
  else:
      newFileName = dirName + '/' + uniquifier + fileName
  
  try:
    os.rename(file, newFileName)
  except Exception, e:
    sys.exit('oops: %s' % e)

  logging.info('file was renamed on disk as %s' % os.path.basename(newFileName))
  logging.info('its location is %s' % dirName)
  
  return {"file_name": os.path.basename(newFileName), "location": dirName}



def statBuildMetaData(file):
  logging.info('trying to stat %s for its size' % file)
  
  try:
    statinfo = os.stat(file)
  except Exception, e:
    sys.exit('oops: %s' % e)

  size = statinfo.st_size
        
  metadata = {"file_name": file, "file_type": "unknown", "file_size": size}
  
  logging.info('just built generic json metadata object for this file %s which will be updated' % metadata)
  
  return metadata



def declareFileLocation(samweb, fileName, location):
  logging.info('trying to declare file location to sam with filename of %s and location of %s' % (fileName, location))
  
  location = samprefix(location) + location

  try:
    samweb.addFileLocation(fileName, location)
  except Exception, e:
    sys.exit('oops: %s' % e)
  logging.info('file location was declared to sam')



def get_tag(options, user):
  logging.info('trying to resolve a tag')
  
  if options.tag:
    tag = options.tag
    logging.info('the tag is %s' % tag)
    return tag
  else:
    tag =  user + "-" + str(datetime.datetime.now().strftime("%Y-%m-%d-%H_%M_%S"))
    logging.info('the tag is %s' % tag)
    return tag



def createDefinition(samweb, definitionName, dimensions):
  logging.info('trying to create definition %s with dimensions %s to sam' % (definitionName, dimensions))
  
  try:
    samweb.createDefinition(definitionName, dimensions)
  except Exception, e:
    sys.exit('oops: %s' % e)
  logging.info('dataset definition created')



class Sam_Metadata_Dumper_Parser:
 
  SAM_JSON_METADATA = None
 
  def __init__(self, file):
    self.file = file
    
    
  def get_json(self):
    logging.info('trying to create subprocess for sam_metadata_dumper')     
   
    try:
      a = json.loads( subprocess.Popen(["sam_metadata_dumper", self.file],stdout=subprocess.PIPE).stdout.read() )
    except Exception, e:
      sys.exit('oops: %s' % e)

    logging.info('extracted the following metadata to be formated %s', a)        

    self.SAM_JSON_METADATA = a[self.file]

    return self.SAM_JSON_METADATA


  def format_json(self):
    logging.info('formatting the extracted metadata')  
  
    keys = self.SAM_JSON_METADATA.keys()
    application = {}
    found = False

    if 'applicationFamily' in keys:
      found = True
      application['family'] = self.SAM_JSON_METADATA['applicationFamily']
      del self.SAM_JSON_METADATA['applicationFamily']
    if 'applicationVersion' in keys:
      found = True
      application['version'] = self.SAM_JSON_METADATA['applicationVersion']
      del self.SAM_JSON_METADATA['applicationVersion']
    if 'process_name' in keys:
      found = True
      application['name'] = self.SAM_JSON_METADATA['process_name']
      del self.SAM_JSON_METADATA['process_name']
    if found:
      self.SAM_JSON_METADATA["application"] = application
                
    if 'dataTier' in keys:
      self.SAM_JSON_METADATA['data_tier'] = self.SAM_JSON_METADATA['dataTier']
      del self.SAM_JSON_METADATA['dataTier']
    if 'fileType' in keys:
      self.SAM_JSON_METADATA['file_type'] = self.SAM_JSON_METADATA['fileType']
      del self.SAM_JSON_METADATA['fileType']
    if 'streamName' in keys:
      self.SAM_JSON_METADATA['data_stream'] = self.SAM_JSON_METADATA['streamName']
      del self.SAM_JSON_METADATA['streamName']

    for key, value in self.SAM_JSON_METADATA.iteritems():
      if isinstance(value, int):
        self.SAM_JSON_METADATA[key] = str(value)
        
    return self.SAM_JSON_METADATA



def check_options(p, options):
  logging.info('checking options')

  if options.name == None:
    p.error("you must specify dataset name")

  if options.file and options.directory:
    p.error("you must specify either a text file or a directory not both")

  if options.file == None and options.directory == None:
    p.error("you must specify either a text file or a directory")

  if options.metadata == None:
    p.error("you must specify metadata json file")

  if options.subprocess != 'sam_metadata_dumper':
    p.error("only sam_metadata_dumper is currently supported")

  logging.info('options good')



def main():
    
  user = getpass.getuser()
  
  """runs program and handles command line options"""

  p = optparse.OptionParser(description='Add a group of files to SAM and create a dataset out of it.',
                            prog='sam_add_dataset',
                            version='sam_add_dataset 0.1',
                            usage='%prog <-f file | -d directory> <-m json file> <-n datasetname> [options]')


  p.add_option('-e', '--experiment', help='use this experiment server defaults to $SAM_EXPERIMENT if not set')
  p.add_option('-u', '--user', help='default is %s' % user)
  p.add_option('-t', '--tag', help='the value for Dataset.Tag which will be used to distinguish this new dataset default format is user+date')
  p.add_option('-n', '--name', help='the dataset name')
  p.add_option('-d', '--directory', help='directory of files to create dataset with')
  p.add_option('-r', '--recurse', action ='store_true', default=False, help='walk down all levels of directory')
  p.add_option('-f', '--file', help='file of file paths to create dataset with')
  p.add_option('-m', '--metadata', help='json file of metadata you would like added to all files')
  p.add_option('-s',  '--subprocess', help='execute a child program in a new process to extract metadata only sam_metadata_dumper currently supported')
  p.add_option('-c', '--cert', help='x509 certificate for authentication. If not specified, use $X509_USER_PROXY, $X509_USER_CERT/$X509_USER_KEY or standard grid proxy location')
  p.add_option('-v', '--verbose', action ='store_true', help='returns verbose output')
  
  
  options, arguments = p.parse_args()

  check_options(p, options)

  
  if options.verbose:
    logging.basicConfig(level=logging.DEBUG)
  else:
    logging.disable(logging.CRITICAL)
  
  
  experiment = get_experiment(options)

  if options.user:
    user = options.user

  cert = get_standard_certificate_path(options)

  samweb = samweb_client.SAMWebClient(experiment=experiment, cert=cert)

  tag = get_tag(options, user)
 
  jsonFile = options.metadata
  
  datasetName = options.name


  logging.info('the options are %s' % options)
  logging.info('the arguments are %s' % arguments)
  logging.info('the user is %s' % user)


  if 5 > 3:  #still need to figure out this condition

    universalMD = getJSONMetadata(options.metadata, tag)

    if options.directory:
      if os.path.isdir(options.directory):
        fileList = getFileListFromDir(options.directory, options.recurse)
    else:
      fileList = getFileList(options.file)
    

    logging.info('entering for loop to process all the files to create the dataset')
    for file in fileList:
      logging.info('processing %s' % file)
      
      fileMD = {}
      
      if options.subprocess:
        dumperObject = Sam_Metadata_Dumper_Parser(file)
        dumperObject.get_json()
        sam_metadata_dumper_metadata = dumperObject.format_json()
        fileMD.update(sam_metadata_dumper_metadata) 
        
      fileMD.update( statBuildMetaData(file) )
      renamedFile = renameFile(file)
      fileLocation = renamedFile.pop("location")
            
      fileMD.update(renamedFile)
      fileMD.update(universalMD)
    
      declareFile(samweb, fileMD)
      declareFileLocation(samweb, fileMD["file_name"], fileLocation)

    logging.info('for loop is done')
    
    
    dimension = "Dataset.Tag " + tag
    createDefinition(samweb, options.name, dimension)


    logging.info('PROGRAM SUCCESS')


  else:
    #p.print_help()
    p.error("incorrect number of arguments")



if __name__ == '__main__':
  main()